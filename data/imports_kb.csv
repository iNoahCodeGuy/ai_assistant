import,category,tier,audience,explanation,enterprise_concern,enterprise_alternative,when_to_switch
openai,llm,1,technical_hiring_manager,"OpenAI SDK provides GPT-4 and embeddings API. Reliable and well-documented for rapid AI development.","Vendor lock-in, data privacy concerns, per-token costs can scale unpredictably.","Azure OpenAI (enterprise SLA), Google Vertex AI, Anthropic Claude, or internal LLM.","When data governance requires regional compliance, or cost optimization needs dedicated endpoints."
openai,llm,2,developer,"OpenAI client initialized with retry logic and exponential backoff. Embeddings use text-embedding-3-small (1536-dim). Chat uses gpt-4-turbo or gpt-3.5-turbo based on config. All calls traced via LangSmith decorators.","Rate limits can throttle during traffic spikes. No VPC endpoints for private networking.","Azure OpenAI with private endpoints, or self-hosted models like Llama 3 via vLLM.","When SLA requires 99.9% uptime or private data cannot leave infrastructure."
openai,llm,3,advanced_technical,"Full trade-off: OpenAI excels at general intelligence but locks vendor choice. Embedding quality excellent for semantic search but costs 0.0001/1k tokens. For enterprise: Azure OpenAI provides HIPAA/SOC2 compliance + VNet integration. Alternative: Vertex AI Gemini for GCP-native workflows or Anthropic for longer context (200k tokens). For cost control: cache embeddings aggressively and implement request batching.","Production concerns: API downtime impacts entire pipeline. No fine-tuning on latest models. Token limits constrain complex prompts.","Hybrid: Azure OpenAI for compliance + Anthropic for complex reasoning + internal embeddings via sentence-transformers.","At >$10k/month API costs, evaluate ROI of self-hosted inference with TensorRT-LLM or vLLM on A100 clusters."
supabase,database,1,technical_hiring_manager,"Supabase combines Postgres database, authentication, and storage in one platform. Perfect for rapid prototyping with built-in real-time subscriptions.","Limited high-availability options on free tier. Row-level security can become complex at scale.","Managed Postgres (Cloud SQL, RDS) + separate auth (Auth0, Okta) + object storage (S3, GCS).","When traffic exceeds 10k QPS or need multi-region active-active replication."
supabase,database,2,developer,"Supabase client created per-request in serverless (stateless). Connection pooling handled by Supabase. Service role key for server-side operations (bypasses RLS). Anon key for client operations (respects RLS). All queries logged to analytics tables for observability.","Connection limits on pooler (max 15 concurrent in free tier). Migrations must be applied manually via SQL editor.","Direct Postgres with pgBouncer pooler + Auth0 + S3, deployed on Cloud Run or ECS with connection pooling at app layer.","When concurrent connections exceed pooler limits or need multi-tenant isolation."
supabase,database,3,advanced_technical,"Architecture decision: Supabase provides excellent DX but introduces single point of failure. For enterprise: separate concerns—use managed Postgres with read replicas, dedicated auth service with SSO, and CDN-backed object storage. Supabase's Realtime uses WebSockets which don't scale horizontally well. For high-throughput: migrate to PostgreSQL on Kubernetes with Patroni for HA, implement custom connection pooling, and use Redis Pub/Sub for real-time features.","Performance bottleneck: all services co-located. No VPC peering. Limited observability into Postgres query plans.","Kubernetes-hosted Postgres (Patroni/CloudNativePG) + Auth0 + S3 with CloudFront CDN + Redis for caching.","When need sub-50ms p99 latency globally, or processing >100M events/day with strict SLAs."
pgvector,vector_db,1,technical_hiring_manager,"pgvector is a Postgres extension for vector similarity search. Keeps vectors alongside structured data for simpler architecture.","Slower than dedicated vector databases at scale. Limited to Postgres query performance.","Pinecone, Weaviate, Qdrant, or Google Vertex AI Matching Engine for production workloads.","When retrieval latency exceeds 500ms or managing >1M embeddings with frequent updates."
pgvector,vector_db,2,developer,"pgvector stores embeddings in Postgres using IVFFLAT index for approximate nearest neighbor search. Custom RPC function match_kb_chunks handles cosine similarity. Index created with lists=100 for ~10k vectors. Query returns top-k with scores. Re-indexing required when data grows >100k rows.","Index maintenance: IVFFLAT requires manual VACUUM and reindexing. No filtered vector search (metadata + similarity).","Pinecone (managed, filtered search) or Qdrant (self-hosted, fast filtering) with metadata pre-filtering.","When need combined metadata + vector filtering, or retrieval latency consistently >200ms."
pgvector,vector_db,3,advanced_technical,"Trade-off analysis: pgvector simplifies stack but doesn't scale past millions of vectors. IVFFLAT index is less accurate than HNSW at high dimensionality. For enterprise: dedicated vector DB provides horizontal scaling, filtered ANN (combine metadata + vector search), and sub-100ms p99 globally. Pinecone handles index sharding automatically. Vertex Matching Engine integrates with GCP IAM. Qdrant offers hybrid search (sparse + dense). Migration path: dual-write to both pgvector and Pinecone, A/B test latency/accuracy, then cutover.","Cost: pgvector compute scales vertically (larger instance). Dedicated vector DBs scale horizontally but add $200-500/month base cost.","Pinecone Standard (managed, $70/1M vectors/month) or Vertex AI Matching Engine (pay-per-query, VPC-native).","At >5M vectors or when p99 latency >500ms. ROI: if saving 200ms per query on 1M daily queries."
langchain,orchestration,1,technical_hiring_manager,"LangChain provides abstractions for LLM workflows. Simplifies prompt management, memory, and retrieval integration.","Heavy dependency footprint. Frequent breaking changes between versions. Vendor-opinionated abstractions.","LangGraph (same vendor, more explicit), LlamaIndex (retrieval-focused), or custom orchestration.","When need fine-grained control over reasoning steps or dependency conflicts arise."
langchain,orchestration,2,developer,"Using compatibility layer (src/core/langchain_compat.py) to handle version migrations. Imports: OpenAIEmbeddings, ChatOpenAI, Document classes. All imports wrapped to prevent breaking changes. Custom prompts defined in PromptTemplate. Retrieval chains use LCEL (LangChain Expression Language) for composability.","Version churn: 0.1.x → 0.2.x broke many imports. Debugging chain internals is opaque (nested callbacks).","LangGraph for explicit state machines, or vanilla Python with structured outputs via Pydantic.","When chain complexity makes debugging difficult, or upgrade path is blocked by breaking changes."
langchain,orchestration,3,advanced_technical,"Architectural assessment: LangChain accelerates prototyping but adds abstraction tax. For production: consider LangGraph for explicit node-based workflows (current implementation uses this pattern). Chains hide control flow; nodes expose it. Enterprise alternative: Temporal for durable execution + custom LLM clients. LangChain's memory patterns don't handle distributed state well. For multi-agent: use message queues (Kafka/SQS) + state store (Redis) + custom orchestration. LangSmith tracing compensates for chain opacity.","Production risk: Nested callbacks make timeouts/retries complex. No native distributed tracing beyond LangSmith.","Temporal.io (durable workflows) + custom LLM wrappers + OpenTelemetry for unified tracing.","When orchestrating >5 agents with complex dependencies, or need workflow replay/debugging at scale."
langgraph,orchestration,1,technical_hiring_manager,"LangGraph extends LangChain with explicit graph-based workflows. Better control over multi-step AI reasoning than chains.","Newer library with smaller community. Documentation still evolving. Limited enterprise tooling.","Apache Airflow (batch), Temporal (stateful workflows), Prefect (modern orchestration), or custom state machines.","When need proven orchestration with enterprise monitoring and scale guarantees."
langgraph,orchestration,2,developer,"Current implementation: 7-node pipeline (classify_query → retrieve_chunks → generate_answer → plan_actions → apply_role_context → execute_actions → log_and_notify). Each node is pure function taking ConversationState and returning updated state. Immutable state pattern prevents side effects. Nodes composed via functional pipeline in conversation_flow.py.","Limited built-in retry/error handling. No distributed execution. State must fit in memory.","Temporal for durable state + retry policies, or Prefect for DAG-based orchestration with automatic retries.","When single-node failures require durable state recovery, or workflows span >10 minutes."
langgraph,orchestration,3,advanced_technical,"Design decision: LangGraph provides excellent local reasoning control but lacks enterprise orchestration features. Nodes are synchronous—blocking. No native support for parallel execution or fan-out/fan-in patterns. For high-throughput: migrate to Temporal with activity workers for each node type. State persistence via Postgres + Temporal's durable execution guarantees at-least-once delivery. For complex multi-agent: implement message-passing via Kafka topics, state snapshots in Redis, and idempotent handlers. LangGraph works for <100 QPS; beyond that, need distributed orchestration.","Scalability ceiling: in-memory state limits throughput. No checkpointing for long-running workflows.","Temporal (durable execution, replay debugging) or custom event-driven architecture with Kafka + Lambda/Cloud Run.","At >100 concurrent workflows or when workflow duration >5 minutes (serverless timeout limits)."
vercel,deployment,1,technical_hiring_manager,"Vercel provides zero-config serverless deployment. Automatic scaling and global CDN. Perfect for rapid iteration and demos.","10-second function timeout limit. No VPC networking. Limited observability compared to full platforms.","Google Cloud Run (containers, 60-min timeout), AWS ECS Fargate (private networking), or Kubernetes (full control).","When need private networking, long-running tasks, or fine-grained IAM controls."
vercel,deployment,2,developer,"Vercel Functions are serverless (stateless, cold start ~1-2s). Code in api/ directory auto-deploys on git push. Environment variables set in dashboard. CORS handled by vercel.json. Logs streamed to dashboard (limited retention). No connection pooling—each request creates new DB client. Timeout: 10s hobby, 60s pro.","Cold starts impact p99 latency. No persistent connections. Function concurrency limited by plan tier.","Cloud Run (same DX, longer timeout, VPC-native) or ECS Fargate (full container control, private subnets).","When p99 latency >2s due to cold starts, or need database connection pooling across requests."
vercel,deployment,3,advanced_technical,"Trade-off analysis: Vercel optimizes for frontend deployment (Next.js) but API routes are serverless functions with constraints. 10s timeout prevents batch jobs. No VPC means can't connect to private databases securely. For enterprise: migrate API routes to Cloud Run (60-min timeout, VPC, connection pooling via sidecar). Keep frontend on Vercel CDN. Alternative: full Kubernetes deployment with Istio service mesh for traffic shaping. Serverless works for <100 RPS; beyond that, need reserved instances (Cloud Run min-instances) or autoscaling containers.","Cost: serverless pricing unpredictable at scale. No SLA guarantees. Limited regional control.","Hybrid: Vercel for static frontend + Cloud Run for API (VPC-connected, longer timeout, connection pooling).","At >500 RPS sustained, or when need sub-100ms p99 with connection pooling and private networking."
resend,email,1,technical_hiring_manager,"Resend is modern email API. Simple integration for transactional emails like resume delivery.","No dedicated IP on free tier. Limited email deliverability controls. Minimal audit logging.","AWS SES (dedicated IP, DKIM/SPF), SendGrid (advanced deliverability), or enterprise SMTP relay.","When sending >10k emails/month or need compliance audit trails."
resend,email,2,developer,"Resend service factory (get_resend_service) handles graceful degradation if API key missing. Email sent via resend.emails.send() with from/to/subject/html. No retry logic currently—fails fast. Logs email_sent action to analytics. Alternative: implement queue (SQS) + retry worker for reliability.","Single point of failure. No bounce/complaint handling. Rate limits per-account.","AWS SES + SNS for bounce notifications + SQS for retry queue, or SendGrid with webhook processing.","When email is mission-critical and need delivery guarantees with automatic retries."
resend,email,3,advanced_technical,"Architecture assessment: Resend simplifies transactional email but lacks enterprise features. For production: AWS SES provides dedicated IPs (improve deliverability), DKIM signing (prevent spoofing), bounce/complaint webhooks (maintain sender reputation), and deep CloudWatch integration. Implement email as async job: user action → SQS message → Lambda worker → SES send → SNS notification on bounce. This decouples email from request path, adds retry logic, and handles failures gracefully. For compliance: store sent emails in S3 with 7-year retention (GDPR/CCPA audit trail).","Reliability: synchronous email blocks request. No automatic retries. Deliverability depends on shared IP reputation.","AWS SES (dedicated IP, $25/month) + SQS + Lambda (async processing) + SNS (bounce handling) + S3 (audit log).","When email delivery must be <1% failure rate, or compliance requires immutable audit logs."
twilio,sms,1,technical_hiring_manager,"Twilio provides SMS API. Used for contact notifications when users request resume.","Cost scales with volume (~$0.0075/SMS US). Regional compliance complexity. No message queueing built-in.","Twilio Messaging Service (scale features), AWS SNS (simpler, lower cost), or Infobip (global reach).","When sending >10k SMS/month or need international delivery with compliance automation."
twilio,sms,2,developer,"Twilio service factory (get_twilio_service) initializes client with account SID and auth token. SMS sent via client.messages.create(). Logs to sms_logs table with status. No retry on failure—errors logged. Alternative: implement queue for reliability and rate limiting.","Synchronous send blocks request. No automatic retry. Rate limits require careful throttling.","Twilio + SQS queue + Lambda worker for async processing with exponential backoff retries.","When SMS is critical path and need delivery guarantees beyond best-effort."
twilio,sms,3,advanced_technical,"Enterprise SMS architecture: decouple from request path via message queue. User action → SQS → Lambda worker → Twilio API → DynamoDB (delivery status). This enables: automatic retries with exponential backoff, rate limiting (respect carrier restrictions), status webhooks (delivery confirmation), and cost tracking per campaign. For compliance: store message content + delivery receipts in S3 with encryption at rest (HIPAA/TCPA). For scale: Twilio Messaging Service provides shared short codes, A2P 10DLC registration (higher throughput), and global number pools. Alternative: AWS SNS for simple use cases (<1k SMS/day) at lower cost.","Compliance risk: A2P 10DLC registration required for bulk US SMS. No automatic opt-out handling.","Twilio Messaging Service (A2P compliance + webhooks) + SQS queue + Lambda + S3 audit log + DynamoDB status tracking.","At >5k SMS/day or when regulatory compliance requires opt-out management and delivery receipts."
langsmith,observability,1,technical_hiring_manager,"LangSmith traces LLM calls for debugging. Shows prompts, completions, latency, and cost per request.","Data egress: traces sent to external service. Limited correlation with infrastructure metrics.","Datadog APM (unified observability) + LangFuse (self-hosted LLM tracing) for data sovereignty.","When need unified tracing across LLM + infrastructure, or data cannot leave private network."
langsmith,observability,2,developer,"LangSmith integration via @trace_generation and @trace_retrieval decorators. Auto-captures: prompt templates, retrieved chunks, LLM responses, latency, token counts. Traces viewable in LangSmith dashboard with conversation threading. Requires LANGSMITH_API_KEY env var. Fallback: decorators no-op if key missing (graceful degradation).","Cost: $39/month for team plan. Traces stored externally (data residency concern). Limited custom metrics.","Datadog with custom LLM span instrumentation + LangFuse (OSS, self-hosted) for cost control.","When need unified APM (infra + LLM) with custom dashboards and alerting."
langsmith,observability,3,advanced_technical,"Observability strategy: LangSmith excels at LLM-specific debugging but doesn't replace full APM. For enterprise: implement hybrid tracing—Datadog for infrastructure (API latency, DB queries, error rates) + LangFuse for LLM traces (prompts, completions, evaluations). Use OpenTelemetry for unified instrumentation. Store traces in private ClickHouse cluster for data sovereignty. Custom metrics: embedding cache hit rate, retrieval relevance scores (NDCG), LLM refusal rate. Alerting: p99 latency >2s, error rate >1%, cost spike >20% vs baseline. For evaluation: run RAGAS metrics (faithfulness, answer relevancy) on production traces weekly.","Vendor lock: LangSmith-specific instrumentation. No SLA. Limited retention on lower tiers.","Self-hosted: Datadog (infra APM) + LangFuse (LLM tracing) + ClickHouse (long-term storage) + Grafana (dashboards) + PagerDuty (alerting).","When data sovereignty required, or observability costs >$500/month, or need custom evaluation pipelines."
streamlit,frontend,1,technical_hiring_manager,"Streamlit provides rapid Python-based UI prototyping. Zero frontend code required. Perfect for demos and internal tools.","Not production-grade for public apps. Limited styling control. Slower than modern JS frameworks.","Next.js (SSR/SPA), React (SPA), or Vue (lightweight) with REST API backend.","When need polished UX, SEO, or high-traffic public deployment."
streamlit,frontend,2,developer,"Streamlit app in src/main.py. Session state for role selection and chat history. Rerun on each interaction (full script execution). No persistent server state—use st.session_state. Deployment: streamlit run src/main.py locally, or Streamlit Cloud for public hosting. Alternative: migrate to Next.js with API routes (api/) already implemented.","Performance: full page rerun on every interaction. No code splitting. Limited mobile responsiveness.","Next.js with React components, Vercel deployment, and API routes in /api directory (already exists).","When demo becomes product and need professional UX with mobile support."
streamlit,frontend,3,advanced_technical,"Architecture decision: Streamlit optimizes for data science prototypes but lacks production frontend features. For enterprise: migrate to Next.js (SSR for SEO, code splitting for performance, Tailwind for styling, NextAuth for auth). Backend already serverless on Vercel—frontend migration is additive. Implementation: extract role selection into Next.js pages/, use SWR for API state management, implement WebSocket for real-time (Supabase Realtime or Pusher). For internal tools: keep Streamlit but deploy behind SSO (Okta) with network restrictions. Streamlit works for <100 DAU; beyond that, performance degrades.","Scalability: Streamlit apps don't scale horizontally well. Each session holds state in memory.","Next.js (SSR/SPA) + SWR (state management) + Tailwind (styling) + NextAuth (SSO) + Vercel deployment.","When DAU >100 or need mobile app, or product UX standards require polished design and accessibility."
supabase_storage,storage,1,technical_hiring_manager,"Supabase Storage provides S3-like object storage. Integrated with Supabase auth for access control.","Limited to Supabase ecosystem. No multi-region replication on free tier. Basic CDN integration.","AWS S3 + CloudFront CDN, Google Cloud Storage + CDN, or Azure Blob Storage.","When need global distribution, advanced lifecycle policies, or multi-region redundancy."
supabase_storage,storage,2,developer,"Storage service (get_storage_service) uploads files via supabase.storage.from_(bucket).upload(). Public URLs for resumes, private for CSVs. RLS policies control access. No automatic CDN—URLs served from Supabase origin. Alternative: migrate to S3 with CloudFront for lower latency globally.","Origin latency varies by user location. No automatic compression. Limited to 50GB on free tier.","S3 Standard tier + CloudFront CDN + Lambda@Edge for image optimization, with presigned URLs for auth.","When serving >1TB or need global p99 latency <100ms with automatic compression."
supabase_storage,storage,3,advanced_technical,"Storage architecture: Supabase Storage works for small-scale but lacks enterprise features. For production: S3 Standard class with intelligent tiering (auto-archive cold data), CloudFront CDN with custom SSL (lower latency), Lambda@Edge for image resizing (reduce bandwidth), S3 lifecycle policies (auto-delete after 90 days), and versioning (audit trail). For compliance: enable S3 Object Lock (WORM for legal hold), encryption at rest (KMS), access logging (audit trail), and signed URLs with expiration (secure sharing). Cost optimization: compress files before upload, use S3 Select for partial reads, implement CDN cache headers.","Data sovereignty: Supabase Storage regions limited. No automatic failover. No lifecycle management.","S3 + CloudFront + Lambda@Edge + KMS encryption + S3 Object Lock + lifecycle policies + VPC endpoints for private access.","When storing >100GB, need <50ms global latency, or compliance requires encryption/audit trails."
pydantic,validation,1,technical_hiring_manager,"Pydantic provides runtime data validation using Python type hints. Prevents bad data from entering the system.","Adds CPU overhead for complex nested models. Can be verbose for simple validation.","Marshmallow (alternative serialization), dataclasses with manual validation, or TypeScript on frontend.","When validation overhead impacts performance, or prefer schema-first design."
pydantic,validation,2,developer,"ConversationState dataclass uses Pydantic for validation. Type hints enforced at runtime. Automatic JSON serialization. Custom validators for email/phone formats. Immutable state via frozen=True. Alternative: use dataclasses for simpler objects without validation.","Validation happens per-instance. Large objects (many fields) add latency. Error messages can be cryptic.","Dataclasses for internal objects, Pydantic only at API boundaries for external input validation.","When profiling shows validation is >10% of request time, or type errors are rare in production."
pydantic,validation,3,advanced_technical,"Validation strategy: Pydantic excels at API boundary validation but adds overhead for internal objects. Best practice: validate once at ingress (API request), use plain dataclasses internally, re-validate at egress (database write). For performance: use Pydantic's model_validate_json() to skip Python object creation. For complex validation: implement custom __get_validators__ with Rust extensions (pydantic-core). For schema management: generate OpenAPI specs from Pydantic models automatically. Alternative: if using GraphQL, leverage schema validation there and skip Pydantic.","Performance: nested model validation is O(n) in object depth. Can cause cold start latency in serverless.","Pydantic at API boundaries + plain dataclasses internally + OpenAPI spec generation + custom Rust validators for hot paths.","When request validation adds >50ms p99 latency, or cold starts exceed 2s due to model loading."