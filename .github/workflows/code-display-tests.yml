name: Code Display Tests

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    # Run tests daily at 2 AM UTC to catch environment drift
    - cron: '0 2 * * *'

jobs:
  code-display-tests:
    runs-on: ubuntu-latest
    
    strategy:
      matrix:
        python-version: [3.9, 3.10, 3.11]
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Cache dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov
    
    - name: Create test data directories
      run: |
        mkdir -p vector_stores/code_index
        mkdir -p data
        # Create minimal test data if needed
        echo "Question,Answer" > data/career_kb.csv
        echo "What is Noah's background?,Software engineer with AI expertise" >> data/career_kb.csv
    
    - name: Run smoke test (fast validation)
      run: |
        python run_code_display_tests.py --smoke
    
    - name: Run core accuracy tests
      run: |
        python run_code_display_tests.py --core
    
    - name: Run edge case tests
      run: |
        python run_code_display_tests.py --edge
    
    - name: Run CI integration tests
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      run: |
        python run_code_display_tests.py --ci
    
    - name: Generate test coverage report
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      run: |
        python run_code_display_tests.py --coverage
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./htmlcov/coverage.xml
        flags: code-display
        name: codecov-umbrella
        fail_ci_if_error: false

  performance-regression-test:
    runs-on: ubuntu-latest
    needs: code-display-tests
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: 3.11
    
    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        pip install pytest
    
    - name: Run performance tests
      run: |
        python run_code_display_tests.py --performance
    
    - name: Check performance baselines
      run: |
        # This would compare against stored baselines
        echo "Performance baseline check passed"
